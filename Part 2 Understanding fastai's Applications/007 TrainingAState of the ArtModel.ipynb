{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27bBexr0Ezwp"
   },
   "source": [
    "- Data augmentation technique:\n",
    "    - Normalization\n",
    "    - Mixup\n",
    "    - Progressive resizing approach\n",
    "    - test time augmentation\n",
    "\n",
    "- Going to train a model from scratch (not using transfer learning)\n",
    "- Using a subset of ImageNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91OSncUYEKQw"
   },
   "source": [
    "## Imagenette\n",
    "If a dataset taking longer to do an experiment, think about how you could cut down your dataset, or simplify your model, to impore your expermentation speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "sVQJZJpm6RXt",
    "outputId": "6144d558-ddae-4b8b-f92a-5c6290f0f85a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1557168128' class='' max='1557161267' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1557168128/1557161267 00:31<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get started with this dataset:\n",
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.IMAGENETTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyw4pPrbZ5Xp",
    "outputId": "29c5eaea-e241-4210-d457-83f18acf57cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1051: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
      "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
      "X = torch.solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve(A, B) (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:766.)\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# get our dataset into a DataLoaders object, using the presizing:\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock(), CategoryBlock()),\n",
    "    get_items=get_image_files,\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(460),\n",
    "    batch_tfms=aug_transforms(size=224, min_scale=0.75)\n",
    ")\n",
    "\n",
    "dls = dblock.dataloaders(path, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "J4HmV782aj_2",
    "outputId": "c7b8650f-6bc3-4577-c4fc-226c4381e55f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.675329</td>\n",
       "      <td>1.779331</td>\n",
       "      <td>0.485810</td>\n",
       "      <td>06:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.248670</td>\n",
       "      <td>1.509915</td>\n",
       "      <td>0.529500</td>\n",
       "      <td>06:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.953398</td>\n",
       "      <td>1.093729</td>\n",
       "      <td>0.631068</td>\n",
       "      <td>06:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.740561</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>0.771098</td>\n",
       "      <td>06:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.605196</td>\n",
       "      <td>0.561991</td>\n",
       "      <td>0.820388</td>\n",
       "      <td>06:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do a training run that will serve as a baseline:\n",
    "\n",
    "model = xresnet50()\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7phmybqhba2u"
   },
   "source": [
    "## Normalization\n",
    "Input data is normalized helps training model:\n",
    "- has a mean of 0\n",
    "- a standard deviation of 1\n",
    "\n",
    "In computer vision libraries use values between but not normalized\n",
    "- 0 and 255 pixels\n",
    "- 0 and 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kge87NHIa9lj",
    "outputId": "30013537-f3b5-4c65-e83f-5db8586d0f93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([0.4680, 0.4675, 0.4215], device='cuda:0'),\n",
       " TensorImage([0.2848, 0.2808, 0.2951], device='cuda:0'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab a batch of data:\n",
    "x,y = dls.one_batch()\n",
    "\n",
    "# look at those values\n",
    "# by averaging over all axes except for the channel axis(axis 1):\n",
    "x.mean(dim=[0,2,3]), x.std(dim=[0,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKVYOEJgfey6"
   },
   "source": [
    "As expected, the mean and standard deviation are not very closs to the desired values.\n",
    "\n",
    "To normalize need to pass to this transform the mean and standard deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VuTrAPw1c6wm",
    "outputId": "0d126b97-1a81-478f-e193-8af5c2cb92fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([-0.1885, -0.1044, -0.0593], device='cuda:0'),\n",
       " TensorImage([1.2236, 1.2316, 1.2718], device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add this transform\n",
    "def get_dls(bs, size):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                       get_items=get_image_files,\n",
    "                       get_y=parent_label,\n",
    "                       item_tfms=Resize(460),\n",
    "                       batch_tfms=[*aug_transforms(size=size, min_scale=0.75),\n",
    "                                   Normalize.from_stats(*imagenet_stats)])\n",
    "    return dblock.dataloaders(path, bs=bs)\n",
    "\n",
    "dls = get_dls(64, 224)\n",
    "\n",
    "# take a look at one batch now:\n",
    "x,y = dls.one_batch()\n",
    "x.mean(dim=[0,2,3]),x.std(dim=[0,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Bv-Rz6sShK20",
    "outputId": "c34bce87-9471-4fef-ecb4-8b6fa4c0673f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.697637</td>\n",
       "      <td>1.593400</td>\n",
       "      <td>0.499253</td>\n",
       "      <td>06:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.314280</td>\n",
       "      <td>1.659077</td>\n",
       "      <td>0.544810</td>\n",
       "      <td>06:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.990840</td>\n",
       "      <td>0.872144</td>\n",
       "      <td>0.717326</td>\n",
       "      <td>06:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.760564</td>\n",
       "      <td>0.726331</td>\n",
       "      <td>0.765497</td>\n",
       "      <td>06:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.614061</td>\n",
       "      <td>0.594109</td>\n",
       "      <td>0.813294</td>\n",
       "      <td>06:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check what effect this had on training our model:\n",
    "\n",
    "model = xresnet50()\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loRbBw6ShiCA"
   },
   "source": [
    "Helped little here, normalization becomes expecially important when using pretrained models.\n",
    "\n",
    "When distribute a model, need to also distribute the statistics used for normalization. If using pretrained model, find out what normalization statistics they used and match them.\n",
    "\n",
    "When using a pretrained model through cnn_learner, the fastai library automatically adds the Normalize transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk1TJACCjEm_"
   },
   "source": [
    "## Progressive Resizing\n",
    "All our training up until now has been done at size 224. We could have begun training at a smaller size before going to that: Progressive resizing: start training using small images(enhence speed) and end training using large images(enhence accuracy).\n",
    "\n",
    "We are trying to get our model to learn to do something a little bit different from what it has learned to do before, by changing the size of image: reminds Transfer Learning\n",
    "\n",
    "Another form of data augmentation.\n",
    "\n",
    "First creat a get_dls func that takes an image size and a batch size, returns DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "_tTSAHWNhegi",
    "outputId": "63162275-507c-4d56-a089-4cd8ec22087d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.939635</td>\n",
       "      <td>1.801803</td>\n",
       "      <td>0.501867</td>\n",
       "      <td>03:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.330091</td>\n",
       "      <td>1.232446</td>\n",
       "      <td>0.630695</td>\n",
       "      <td>03:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.979738</td>\n",
       "      <td>0.873671</td>\n",
       "      <td>0.720687</td>\n",
       "      <td>03:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.750537</td>\n",
       "      <td>0.657811</td>\n",
       "      <td>0.809186</td>\n",
       "      <td>03:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create your DataLoaders with a small size\n",
    "dls = get_dls(128,128)\n",
    "learn = Learner(dls, xresnet50(), loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy)\n",
    "\n",
    "# train for fewer epochs than you might otherwise do:\n",
    "learn.fit_one_cycle(4, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "Gw_F9yHSma--",
    "outputId": "34d5a26f-517d-42e8-9c6d-aa96196f122f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.816524</td>\n",
       "      <td>0.820110</td>\n",
       "      <td>0.751680</td>\n",
       "      <td>06:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.669446</td>\n",
       "      <td>0.769156</td>\n",
       "      <td>0.769604</td>\n",
       "      <td>06:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.674326</td>\n",
       "      <td>0.947356</td>\n",
       "      <td>0.726288</td>\n",
       "      <td>06:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.591393</td>\n",
       "      <td>0.589485</td>\n",
       "      <td>0.818148</td>\n",
       "      <td>06:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>0.478636</td>\n",
       "      <td>0.850261</td>\n",
       "      <td>06:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.430764</td>\n",
       "      <td>0.452525</td>\n",
       "      <td>0.861464</td>\n",
       "      <td>06:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dffthen replace the DataLoaders inside the Learner\n",
    "learn.dls = get_dls(64, 224)\n",
    "# fine-tune:\n",
    "learn.fine_tune(5, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GM5vuWVEpKDq"
   },
   "source": [
    "Getting much better performance, and the initial training on small images was much faster on each epoch.\n",
    "\n",
    "For transfer learning, progressive resizing hurt performance(trained on similar-sized images)\n",
    "\n",
    "If transfer learning task is going to use images that are of different sizes, shapes or styles that those used in ther pretaining task, progressive resizing will probably help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SWreIDyrxgl"
   },
   "source": [
    "## Test Time Augmentation\n",
    "- random cropping: fastai will automatically use center-cropping for the validation set-largest square area in the center of the image. Problem: critical features cropped out\n",
    "- Simply squish or stretch the rectangular images to fit into a square space. Difficult for our model, because it has to learn how to recognize squished and squeezed images.\n",
    "- Select a number of areas to crop from the original rectangular image, pass through model and take the max or avg of the predictions. This is known as test time augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "PZkFiCXhpFvU",
    "outputId": "1d7b221c-aa3b-4f22-e87c-4a3035d92fb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8629574179649353"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass any DataLoader to fastai's tta method, by default it will use your validation set:\n",
    "preds, targs = learn.tta()\n",
    "accuracy(preds, targs).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM0FL2dkuPiV"
   },
   "source": [
    "TTA gives a boost in performance, with no additional training required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdlzwKnfulbf"
   },
   "source": [
    "## Mixup\n",
    "Data augmentation technique that can provide higher accuracy, especially when don't have much data and pretrained model(trained on data similar to dataset).\n",
    "\n",
    "It's helpful to have data augmentation techniques that \"dial up\" or \"dial down\" the amount of change, to see what works best for u.\n",
    "\n",
    "Mixup works as follows, for each image:\n",
    "1. Select another image from your dataset at random.\n",
    "2. Pich a weight at random.\n",
    "3. Take a weighted average of the selected image with your image; independent var.\n",
    "4. Take a weighted avg of this image's labels with your image's labels; dependent var.\n",
    "\n",
    "In pseudocode:\n",
    "```\n",
    "image2,target2 = dataset[randint(0,len(dataset)]\n",
    "t = random_float(0.5,1.0)\n",
    "new_image = t * image1 + (1-t) * image2\n",
    "new_target = t * target1 + (1-t) * target2\n",
    "```\n",
    "\n",
    "0.3xchurch + 0.7xgas_station: get linear combination of one-hot-encoded targets:\n",
    "\n",
    "The one-hot-encoded representations are as follows:\n",
    "```\n",
    "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0] and [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "```\n",
    "Here is our final target:\n",
    "```\n",
    "[0, 0, 0.3, 0, 0, 0, 0, 0.7, 0, 0]\n",
    "```\n",
    "\n",
    "This all done for us inside fastai by adding a callback(inject custom behaviour in the training loop) to our Learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "G0Sz4lnvmr94",
    "outputId": "a99f84e7-ec2d-41d5-f1fe-77cd46c8d3fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.185049</td>\n",
       "      <td>2.679157</td>\n",
       "      <td>0.326736</td>\n",
       "      <td>03:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.735136</td>\n",
       "      <td>1.690184</td>\n",
       "      <td>0.517550</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.487736</td>\n",
       "      <td>1.058351</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.335943</td>\n",
       "      <td>0.863896</td>\n",
       "      <td>0.723674</td>\n",
       "      <td>03:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.223124</td>\n",
       "      <td>0.733150</td>\n",
       "      <td>0.785287</td>\n",
       "      <td>03:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here is how to train a model with Mixup:\n",
    "\n",
    "model = xresnet50()\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(),\n",
    "                metrics=accuracy, cbs=MixUp)\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Khfzz59U18D8"
   },
   "source": [
    "## Label Smoothing\n",
    "replace all our 1s with a number a bit less that 1 and our 0s with a number a bit more than 0, and then train. This is called Label Smoothing.\n",
    "\n",
    "In our Imagenette example that has 10 classes, the targets become something like this:\n",
    "```\n",
    "[0.01, 0.01, 0.01, 0.91, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "J_BkPFsS0W_c",
    "outputId": "06efb5cf-2d8b-4065-e4cc-8173a5716658"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.736039</td>\n",
       "      <td>2.858540</td>\n",
       "      <td>0.455190</td>\n",
       "      <td>03:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.229111</td>\n",
       "      <td>2.372200</td>\n",
       "      <td>0.560120</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.959794</td>\n",
       "      <td>1.908748</td>\n",
       "      <td>0.675504</td>\n",
       "      <td>03:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.755817</td>\n",
       "      <td>1.660063</td>\n",
       "      <td>0.784914</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.628465</td>\n",
       "      <td>1.584881</td>\n",
       "      <td>0.821135</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use this in practice, have to change the loss fn in our call to Learner:\n",
    "\n",
    "model = xresnet50()\n",
    "learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropy(),\n",
    "                metrics=accuracy)\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9DiU-_l4UTs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "007_TrainingAState-of-the-ArtModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
